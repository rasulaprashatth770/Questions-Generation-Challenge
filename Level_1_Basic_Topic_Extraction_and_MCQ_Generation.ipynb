{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2l9bd6FOQIv",
        "outputId": "5d77aa1e-dd35-405f-b631-baad8226ebe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf2 transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Function to extract main topics using T5\n",
        "def extract_topics_with_t5(text, model, tokenizer, num_topics=5):\n",
        "    prompt = f\"Extract {num_topics} main topics from the text:\\n{text[:512]}\"\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(inputs, max_length=150, num_beams=4, early_stopping=True)\n",
        "    topics = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return [topic.strip() for topic in topics.split(\"\\n\") if topic.strip()]\n",
        "\n",
        "# Function to generate MCQs for a topic\n",
        "def generate_mcqs_with_t5(topic, context, model, tokenizer, num_questions=5):\n",
        "    prompt = (\n",
        "        f\"Generate {num_questions} multiple-choice questions based on the topic '{topic}' \"\n",
        "        f\"from the following context:\\n{context[:512]}.\\n\"\n",
        "        \"Provide each question with 4 options (A, B, C, D), and specify the correct answer. \"\n",
        "    )\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(inputs, max_length=512, num_beams=4, early_stopping=True)\n",
        "    mcqs = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return mcqs\n",
        "\n",
        "# Main function\n",
        "def process_book_with_t5(pdf_path, model_name=\"t5-base\"):\n",
        "    book_title = \"Project Management Professional Guide\"\n",
        "    output_dir = \"output\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load T5 model and tokenizer\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name,legacy=True)\n",
        "\n",
        "    # Extract text from PDF\n",
        "    book_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Extract main topics\n",
        "    main_topics = extract_topics_with_t5(book_text, model, tokenizer)\n",
        "\n",
        "    # Save topics to JSON\n",
        "    topics_data = {\n",
        "        \"book_title\": book_title,\n",
        "        \"total_topics\": len(main_topics),\n",
        "        \"extraction_timestamp\": datetime.now().isoformat(),\n",
        "        \"main_topics\": main_topics,\n",
        "    }\n",
        "    with open(os.path.join(output_dir, \"topics.json\"), \"w\") as f:\n",
        "        json.dump(topics_data, f, indent=4)\n",
        "\n",
        "    # Generate MCQs\n",
        "    questions = []\n",
        "    for idx, topic in enumerate(main_topics, start=1):\n",
        "        mcqs = generate_mcqs_with_t5(topic, book_text, model, tokenizer)\n",
        "        for i, mcq in enumerate(mcqs.split(\"\\n\\n\"), start=1):\n",
        "            if mcq.strip():  # Skip empty entries\n",
        "                mcq_lines = mcq.split(\"\\n\")\n",
        "                question = {\n",
        "                    \"id\": f\"Q{idx}_{i}\",\n",
        "                    \"topic\": topic,\n",
        "                    \"type\": \"MCQ\",\n",
        "                    \"question\": mcq_lines[0].strip(),\n",
        "                    \"options\": [line.strip() for line in mcq_lines[1:5]],\n",
        "                    \"correct_answer\": mcq_lines[5].strip() if len(mcq_lines) > 5 else None,\n",
        "                    \"page_number\": None,  # Page numbers can be integrated with additional logic\n",
        "                }\n",
        "                questions.append(question)\n",
        "\n",
        "    # Save questions to JSON\n",
        "    questions_data = {\n",
        "        \"metadata\": {\n",
        "            \"generated_at\": datetime.now().isoformat(),\n",
        "            \"total_questions\": len(questions),\n",
        "            \"book_title\": book_title,\n",
        "            \"tool_used\": model_name,\n",
        "        },\n",
        "        \"questions\": questions,\n",
        "    }\n",
        "    with open(os.path.join(output_dir, \"questions.json\"), \"w\") as f:\n",
        "        json.dump(questions_data, f, indent=4)\n",
        "\n",
        "    print(\"Topics and questions generated successfully!\")\n",
        "\n",
        "# Run the script\n",
        "pdf_path = \"/content/Project Management.pdf\"\n",
        "process_book_with_t5(pdf_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OdRiE8rORlD",
        "outputId": "bbb1f399-6ff4-4239-8c15-b6946cce003b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics and questions generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzpTPegZP3xk",
        "outputId": "a223a56d-07f0-4f5f-fab8-108f1b063dfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "haXR-DuLV6vy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}